\chapter{Hotmoka nodes}\label{ch:hotmoka_nodes}

A Hotmoka node is a device that implements an interface for running Java code
remotely. It can be any kind of device, such as a device of an IoT network,
but also a node of a blockchain. We have already used instances of Hotmoka nodes,
namely, instances of \texttt{RemoteNode}. But there are other examples of nodes, that we
will describe in this chapter.

The interface \texttt{io.hotmoka.node.api.Node}\index{Node@{\texttt{Node}}}
is shown in the topmost part of Fig.~\ref{fig:node_hierarchy}.
That interface can be split in five parts:
%
\begin{enumerate}
\item A \emph{get} part, that includes methods for querying the
	state of the node and for accessing the objects contained in its store.
\item An \emph{add} part, that expands the store of the node with the result of a transaction.
\item A \emph{run} part, that runs transactions that execute
	\texttt{@View}\index{View@{\texttt{View}}} methods and hence do not
   	expand the store of the node.
\item A \emph{post} part, that expands the store of the node with the result of a transaction,
	without waiting for its result; instead, a future is returned.
\item A \emph{contextual} part, that allows users to subscribe listeners of events generated during
	the execution of the transactions, or to subscribe listeners called when the node gets closed, or
	to close the node itself.
\end{enumerate}

\begin{figure}[th!]
  \begin{center}
	\begin{tikzpicture}[scale=1]
	\scriptsize
	\externalclasscolor
	\begin{interface}[text width=2.2cm]{Autocloseable}{-4,0}
		\operation{close()}
	\end{interface}
	\begin{interface}[text width=6.6cm]{OnCloseHandlersContainer}{3,0}
		\operation{addOnCloseHandler(OnCloseHandler handler)}
		\operation{removeOnCloseHandler(OnCloseHandler handler)}
	\end{interface}
	\interfacecolor
	\begin{interface}[text width=16cm]{Node}{0,-2.2}
		\inherit{Autocloseable}
		\inherit{OnCloseHandlersContainer}
		\operation{getInfo():NodeInfo}
		\operation{getConfig():ConsensusConfig<?,?>}
		\operation{getTakamakaCode():TransactionReference}
		\operation{getManifest():StorageReference}
		\operation{getClassTag(object:StorageReference):ClassTag}
		\operation{getState(StorageReference object):Stream<Update>}
		\operation{getIndex(StorageReference object):Stream<TransactionReference>}
		\operation{getRequest(reference:TransactionReference):TransactionRequest<?>}
		\operation{getResponse(reference:TransactionReference):TransactionResponse}
		\operation{getPolledResponse(reference:TransactionReference):TransactionResponse}
		\operation{addJarStoreInitialTransaction(request:JarStoreInitialTransactionRequest):TransactionReference}
		\operation{addGameteCreationTransaction(request:GameteCreationTransactionRequest):StorageReference}
		\operation{addInitializationTransaction(request:InitializationTransactionRequest)}
		\operation{addJarStoreTransaction(request:JarStoreTransactionRequest):TransactionReference}
		\operation{addConstructorCallTransaction(request:ConstructorCallTransactionRequest):StorageReference}
		\operation{addInstanceMethodCallTransaction(request:InstanceMethodCallTransactionRequest):Optional<StorageValue>}
		\operation{addStaticMethodCallTransaction(request:StaticMethodCallTransactionRequest):Optional<StorageValue>}
		\operation{runInstanceMethodCallTransaction(request:InstanceMethodCallTransactionRequest):Optional<StorageValue>}
		\operation{runStaticMethodCallTransaction(request:StaticMethodCallTransactionRequest):Optional<StorageValue>}
		\operation{postJarStoreTransaction(request:JarStoreTransactionRequest):JarFuture}
		\operation{postConstructorCallTransaction(request:ConstructorCallTransactionRequest):ConstructorFuture}
		\operation{postInstanceMethodCallTransaction(request:InstanceMethodCallTransactionRequest):MethodFuture}
		\operation{postStaticMethodCallTransaction(request:StaticMethodCallTransactionRequest):MethodFuture}
		\operation{subscribeToEvents(creator:StorageReference, handler:BiConsumer<StorageReference, StorageReference>):Subscription}
	\end{interface}
	\packagecolor
	\begin{package}{Local implementations}
		\begin{interface}[text width=2.7cm]{MokamintNode}{-6.5,-12.5}
			\interfacecolor
			\inherit{Node}
		\end{interface}
		\begin{interface}[text width=2.7cm]{TendermintNode}{-3.4,-12.5}
			\interfacecolor
			\inherit{Node}
		\end{interface}
		\begin{interface}[text width=2.3cm]{DiskNode}{-0.5,-12.5}
			\interfacecolor
			\inherit{Node}
		\end{interface}
	\end{package}
	\packagecolor
	\begin{package}{Adaptors}
		\begin{interface}[text width=2.5cm]{RemoteNode}{7,-12.5}
			\interfacecolor
			\inherit{Node}
		\end{interface}
	\end{package}
	\packagecolor
	\begin{package}{Decorators}
		\begin{interface}[text width=3.5cm]{InitializedNode}{-6,-15}
			\interfacecolor
			\inherit{Node}
			\operation{gamete():StorageReference}
		\end{interface}
		\begin{interface}[text width=5cm]{AccountsNode}{-0.6,-15}
			\interfacecolor
			\inherit{Node}
			\operation{accounts():Stream<StorageReference>}
			\operation{privateKeys():Stream<PrivateKey>}
			\operation{account(i:int):StorageReference}
			\operation{privateKey(i:int):PrivateKey}
		\end{interface}
		\begin{interface}[text width=5cm]{JarsNode}{5.5,-15}
			\interfacecolor
			\inherit{Node}
			\operation{jars():Stream<TransactionReference>}
			\operation{jar(i:int):TransactionReference}
		\end{interface}
	\end{package}
	\end{tikzpicture}
  \end{center}
  \caption{The hierarchy of Hotmoka nodes.}
  \label{fig:node_hierarchy}
\end{figure}

If a node belongs to a blockchain, then all nodes of the blockchain have the same vision
of the state, so that it is equivalent to call a method on a node or on any other node of the
network. The only methods that are out of consensus, since they deal with information specific
to each node, are \texttt{getInfo()}\index{getInfo()@{\texttt{getInfo()}}}, that returns
specific information about the node, and the four contextual methods
\texttt{subscribeToEvents()}\index{subscribeToEvents()@{\texttt{subscribeToEvents()}}},
\texttt{addOnCloseHandler()}\index{addOnCloseHandler()@{\texttt{addOnCloseHandler()}}},
\texttt{removeOnCloseHandler()}\index{removeOnCloseHandler()@{\texttt{removeOnCloseHandler()}}}
and \texttt{close()}\index{close()@{\texttt{close()}}}.

Looking at Fig.~\ref{fig:node_hierarchy}, it is possible to see that
the \texttt{Node} interface has many implementations, that we describe below.

\begin{description}
\item[Local implementations.]\index{node!local}
These are actual nodes that run on the machine
where they have been started. For instance, they can be a node
of a larger blockchain network. Among them,
\texttt{MokamintNode}\index{MokamintNode@{\texttt{MokamintNode}}}
implements a node of a Mokamint\index{Mokamint} blockchain (Sec.~\ref{sec:hotmoka_mokamint});
\texttt{TendermintNode}\index{TendermintNode@{\texttt{TendermintNode}}}
implements a node of a Tendermint\index{Tendermint} blockchain (Sec.~\ref{sec:hotmoka_tendermint})
and will be presented in Sec.~\ref{sec:tendermint_nodes};
\texttt{DiskNode}\index{DiskNode@{\texttt{DiskNode}}}
implements a single-node blockchain in disk memory: this
is useful for debugging, testing and learning, since it allows
one to inspect the content of blocks, transactions and store;
it will be presented in Sec.~\ref{sec:disk_nodes}.
Local nodes can be instantiated through the static
factory methods of their supplier classes
\texttt{MokamintNodes}\index{MokamintNodes@{\texttt{MokamintNodes}}},
\texttt{TendermintNodes}\index{TendermintNodes@{\texttt{TendermintNodes}}} and
\texttt{DiskNodes}\index{DiskNodes@{\texttt{DiskNodes}}}.
Those methods requires to specify
parameters that are specific to the given node
of the network that is being started
and can be different from node to node
(\texttt{MokamintNodeConfig}\index{MokamintNodeConfig@{\texttt{MokamintNodeConfig}}} and similar).
Some implementations have to ability to \emph{resume}.
This means that they recover the state at the end of a previous execution, reconstruct the
consensus parameters from that state and resume the execution from there, downloading
and verifying blocks already processed by the network.
%
\item[Decorators.]\index{node!decorator}
The \texttt{Node}\index{Node@{\texttt{Node}}} interface is implemented by some decorators as well.
Typically, these decorators run some transactions on the decorated node,
to simplify some tasks, such as the initialization of the node, the installation of jars into the node
or the creation of accounts in the node. These decorators are views of the decorated node, in the sense
that any method of the \texttt{Node} interface, invoked on the decorator, is forwarded
to the decorated node, with the exception of the contextual methods that are executed locally
on the specific node where they are invoked.
We will discuss them in Sec.~\ref{sec:node_decorators}.
%
\item[Adaptors.]\index{node!adaptor}
Very often, one wants to \emph{publish} a node online,
so that he (and other programmers who need its service) can use it concurrently.
This should be possible for all implementations of the
\texttt{Node}\index{Node@{\texttt{Node}}} interface,
such as \texttt{DiskNode}\index{DiskNode@{\texttt{DiskNode}}},
\texttt{MokamintNode}\index{MokamintNode@{\texttt{MokamintNode}}},
\texttt{TendermintNode}\index{TendermintNode@{\texttt{TendermintNode}}}
and all present and future implementations.
In other words, one would like to publish \emph{any}
Hotmoka node as a service, accessible through the internet. This will be the subject
of Sec.~\ref{sec:node_services}.
Conversely, once a Hotmoka node has been published at some URI, say
\url{ws://my.company.com}, it will be accessible through a network connection. This complexity
might make it complex, for a programmer, to use the published node.
In that case, we can create an instance of the node that operates as
a proxy to the network service, helping programmers integrate
their software to the service in a seamless way. This \emph{remote} node still implements
the \texttt{Node} interface, but simply forwards all its calls to the remote service
(with the exception of the contextual methods, that are executed locally on
the remote node itself). By programming against
the same \texttt{Node} interface, it becomes easy for a programmer
to swap a local node with a remote node, or vice versa. This mechanism is described
in Sec.~\ref{sec:remote_nodes},
where the adaptor interface \texttt{RemoteNode} in Fig.~\ref{fig:node_hierarchy} is presented.
\end{description}

\section{Tendermint nodes}\label{sec:tendermint_nodes}

This section shows how you can start your own Hotmoka Tendermint node,
consisting of a single validator node, hence part of its own blockchain.
The process is not difficult but is a bit tedious,
because it requires one to install Tendermint and to create
its configuration files. Sec.~\ref{sec:hotmoka_tendermint}
provides a simpler alternative for reaching the same goal, by using docker.

\begin{commentbox}
We strongly suggest you to use docker to install Hotmoka nodes, instead of the instructions
in this section, hence please
follow the instructions in Sec.~\ref{sec:hotmoka_tendermint}.
The current section only exists in order to understand what happens inside the docker container.
If you are not a developer, or if you are not interested in the topic, you can safely
skip this section.
\end{commentbox}

In order to use a Tendermint Hotmoka node, the Tendermint executable must be
installed in our machine, or our experiments will fail. The Hotmoka node
works with Tendermint version \tendermintVersion{}, that can be downloaded in executable
form from \url{https://github.com/tendermint/tendermint/releases/tag/v\tendermintVersion}.
Be sure that you download the executable for the architecture of your computer
and install it at a place that is
part of the command-line path of your computer. You can then verify that Tendermint is
correctly installed:
%
\inputCommand{tendermint_version}
\inputOutput{tendermint_version}

Before starting a local node of a Hotmoka blockchain based on Tendermint, you
need to create the Tendermint configuration file. For instance, in order
to run a single validator node with no non-validator nodes, you can create
its configuration files as follows:
%
\inputCommand{tendermint_testnet}
\inputOutput{tendermint_testnet}
%
This has created a directory \texttt{mytestnet/node0}
for a single Tendermint node, that includes the configuration
of the node and its private and public validator keys.

Once this is done, you can create a key pair for the \emph{gamete}\index{gamete}
of the node that you are going to start. This is an account that holds all initial
crypto coins, if any. You perform this with moka:
%
\index{moka!keys create@{\texttt{keys create}}}
\inputCommand{moka_keys_create_gamete}
\inputOutput{moka_keys_create_gamete}

You can start now a Hotmoka node based on Tendermint,
that uses the Tendermint configuration
directory that you have just created, and with a gamete controlled
by the \texttt{gamete.pem} key pair,
by using the \texttt{moka nodes tendermint init} command. You need
to specify the jar of the runtime of Takamaka, that will
be stored inside the node as \texttt{takamakaCode}: we use the
local Maven's cache for that but you can alternatively download the
\texttt{io.takamaka-code-\takamakaVersion{}.jar} file from Maven and refer to
it in the following command line:
%
\index{moka!nodes tendermint init@{\texttt{nodes tendermint init}}}
\inputCommand{moka_nodes_tendermint_init}
\inputOutput{moka_nodes_tendermint_init}

This command has done a lot! It has created an instance
of \texttt{TendermintNode}; it has stored the
\texttt{io-takamaka-code-\takamakaVersion{}.jar} file
inside it; it has created
a Java object, called manifest, that contains other objects, including
an externally-owned account gamete, whose public key is
that provided with \texttt{-{}-public-key-of-gamete};
it has initialized the balance of the gamete to
the a default initial supply. Finally, this command
has published an internet service at the URI \url{ws://localhost:8001},
reachable through websocket connections, that exports the API of the node.

\begin{commentbox}
By default, \texttt{moka nodes tendermint init} publishes the service at port 8001.
This can be changed with its \texttt{-{}-port} option. Moreover, it uses a default
initial supply for the gamete that can be changed with the \texttt{-{}-initial-supply} option.
Finally, it uses a Hotmoka chain identifier identical to that of the underlying Tendermint
network, specified inside the Tendermint configuration files created by \texttt{tendermint testnet}.
If you want to override it, you can either
edit such configuration files or use the \texttt{-{}-chain-id} option (in the latter case,
the chain identifiers of Hotmoka and Tendermint may be different, which is perfectly fine).
\end{commentbox}

In order to use the gamete, you should bind its key to its actual storage
reference in the node, on your local machine. Open another shell,
move inside the directory holding the keys of the gamete and run:
%
\index{moka!keys bind@{\texttt{keys bind}}}\index{key!binding}
\inputCommand{moka_keys_bind_gamete}
\inputOutput{moka_keys_bind_gamete}
%
This operation has created a pem file whose name is that of the storage reference of the gamete.
With this file, it is possible to run transactions on behalf of the gamete.
%
\begin{commentbox}
You do not need the \texttt{-{}-uri} option above, since \url{ws://localhost:8001} is the default
URI for moka.
\end{commentbox}

Your computer exports a Hotmoka node now, running on Tendermint. You can verify this with
\texttt{moka nodes manifest show}.
Moreover, if your computer is reachable at some address \texttt{my.machine}
and if its 8001 port is open to the outside world,
then anybody can contact
your node at \url{ws://my.machine:8001}, query your node and run transactions on it.
However, what has been created is a Tendermint node where all initial coins are inside
the gamete. By using the gamete, \emph{you} can fill the node with objects
and accounts now, and in general run all transactions you want.
However, other users, who do not know the keys of the gamete,
will not be able to run any non-\texttt{@View} transaction on your node.
If you want to open a faucet\index{faucet}, so that other users can gain droplets of coins
(see examples in Sec.~\ref{sec:creation_account}),
you must add the \texttt{-{}-open-unsigned-faucet} option to the \texttt{moka nodes tendermint init}
command above. If you do that, you can then go into another shell (since the previous one is busy with the
execution of the node), in a directory holding the key pair file of the gamete, and type:
%
\index{moka!nodes faucet@{\texttt{nodes faucet}}}
\inputCommand{moka_nodes_faucet}
\inputOutput{moka_nodes_faucet}
%
This set the maximal amount of coins that
the faucet is willing to give away at each request (its \emph{flow}). You can re-run the
\texttt{moka nodes faucet}
command many times, in order to change the flow of the faucet, or close it completely.
Needless to say, only the owner of the keys of the gamete can run the \texttt{moka nodes faucet} command,
which is why the key pair file of the gamete must be in the directory where you run it.

After opening a faucet with a sufficient flow, anybody can
re-run, for instance, the examples of Ch.~\ref{ch:getting_started_with_hotmoka} by replacing
\texttt{\serverMokamint{}} with \url{ws://my.machine:8001}: your computer will serve
the requests and run the transactions.

If you turn off your Hotmoka node based on Tendermint, its state remains saved inside the
\texttt{chain} directory: the \texttt{chain/tendermint} subdirectory is where Tendermint stores the blocks
of the chain; while \texttt{chain/hotmoka} contains the Xodus database,
consisting of the storage objects created in blockchain.
Try for instance to stop the Tendermint node that we initialized before
(press enter in the window where it was running).
You can subsequently resume that node from its latest state, by typing:
%
\index{moka!nodes tendermint resume@{\texttt{nodes tendermint resume}}}
\inputCommand{moka_nodes_tendermint_resume}
\inputOutput{moka_nodes_tendermint_resume}

There is a log file that can be useful to check the state of our Hotmoka-Tendermint node.
Namely, \texttt{tendermint.log} contains the log of Tendermint itself. It can be interesting
to inspect which blocks are committed and when:
%
\begin{shellbox}\begin{ttlst}
I[2025-06-11|10:13:24.143] Version info, module=main
  tendermint_version=@tendermint_version block=11 p2p=8
I[2025-06-11|10:13:24.169] Started node module=main
  nodeInfo="{ProtocolVersion:{P2P:8 Block:11 App:0}
I[2025-06-11|10:13:25.234] executed block module=state
  height=630 num_valid_txs=2 num_invalid_txs=0
I[2025-06-11|10:13:25.408] committed state module=state
  height=630 num_txs=0
  app_hash=A30F89457141AB7E94F71456871396FD9D30CA8E9F66998C6E3E3079D40849F
\end{ttlst}\end{shellbox}
%
In this log, the block height increases and the application hash changes,
reflecting the fact that the state has been modified.

\subsection{Shared entities}\label{subsec:shared_entities}

This section describes how the set of validators
is implemented in Hotmoka. Namely, the validation power\index{validation power} of the network is expressed as a
total quantity shared among all validator nodes. For instance, when we have shown the manifest of the
nodes (\texttt{moka nodes manifest show}), we have seen information about the only validator in the subsequent form:
%
\begin{shellbox}\begin{ttlst}
validator #0: b437832a688dbb89b145d380b7cb3eb841d7cb09fb600d27be43cd670e8b43f9#0
  id: 030203B36BA4EDF0182D7D40D7EA7FE34A9415B4
  balance: 1568
  staked: 4704
  power: 1000000
\end{ttlst}\end{shellbox}
%
This means that validator \#0 has a \emph{power} of 1000000. If it were the only validator of the network,
also the total power of the validators of the network would be 1000000.
A validator can decide to sell part of its power or all its power to
another validator, resulting in a network with a single (different) validator or with more validators.
For instance, it might sell 200000 units of power to another validator \#1, resulting
in a network with two validators: validator \#0 with 800000 units of power and
validator \#1 with 200000 units of power.

What said above means that the set of validators are a sort of \emph{entity} that shares validation
power among the single validators. Validation power can be sold and bought. The number of
validators and their power is consequently dynamic. In some sense, this mechanism
resembles the market of shares of a corporation.

\begin{figure}[th]
  \begin{center}
    \myincludegraphics{0.8\textwidth}{entities}
  \end{center}
  \caption{The hierarchy of entities and validators classes.}
  \label{fig:entities_hierarchy}
\end{figure}

Hotmoka has an interface that represents entities whose shares can be dynamically sold and bought
among \emph{shareholders}. Fig.~\ref{fig:entities_hierarchy} shows this
\texttt{SharedEntity}\index{SharedEntity@{\texttt{SharedEntity}}}\index{shared entity}
interface. As you can see in the figure, the notion of validators\index{validator}
is just a special case of shared entity (see also~\cite{SpotoMGB23}).
It is possible to use shared entities to represent other concepts, such as
a distributed autonomous organization, or a voting community.
Here, however, we focus on their use to represent the set
of the validators of a proof of stake blockchain.

In general, two concepts are specific to each implementation of shared entities:
who are the potential shareholders and how offers for selling shares work.
Therefore, two generic types specify the interface \texttt{SharedEntity<S,O>}:
\texttt{S} is the type of the shareholders and \texttt{O} is the type of the sale offers of shares.
The \texttt{SharedEntityView}\index{SharedEntityView@{\texttt{SharedEntityView}}}
interface at the top of the hierarchy in Fig.~\ref{fig:entities_hierarchy} defines
the read-only operations on a shared entity. This view is static, in the sense
that it does not specify the operations for transfers of shares. Therefore, its
only type parameter is \texttt{S}: any contract can play the role of the type for the
shareholders of the entity. Method \texttt{getShares()} yields the current
shares of the entity (who owns how much).
Method \texttt{isShareholder()} checks if an object is a shareholder. Method
\texttt{sharesOf()} yields the number of shares that a shareholder owns. As typical in Takamaka,
the \texttt{snapshot()} method allows one to create a frozen read-only copy of an entity
(in constant time), useful when an entity must be queried from a client without
the risk of race conditions if another client is modifying the same entity concurrently.

The \texttt{SharedEntity} subinterface adds methods for transfer of shares.
It includes an inner class \texttt{Offer}\index{Offer@{\texttt{Offer}}}
that models sale offers: it specifies
who is the seller of the shares, how many shares are being sold, the requested
price and the expiration of the offer. Method \texttt{isOngoing()} checks if an offer has
not expired yet. Implementations can subclass \texttt{Offer} if they need more specific
offers. Offers can be placed on sale by calling the \texttt{place()} method with a sale
offer. This method is annotated as \texttt{@FromContract} since the caller must be
identified as the owner of the shares
(or otherwise anybody could sell the shares of anybody else) and as
\texttt{@Payable} so that implementations can require to pay a ticket to place shares on
sale. The sale offer is passed as a parameter to \texttt{place()}, hence it must have been
created before calling that method. The set of all sale offers is available through
\texttt{getOffers()}. Method \texttt{sharesOnSaleOf()} yields the cumulative number of shares on
sale for a given shareholder. Who wants to buy shares calls method \texttt{accept()} with
the accepted offer and with itself as \texttt{buyer}
and becomes a new shareholder or increases its cumulative number of shares
(if it was already a shareholder). Also this method is \texttt{@Payable}, since its caller
must pay \texttt{ticket >= offer.cost} coins to the seller. This means that shareholders
must be able to receive payments and that is why \texttt{S extends PayableContract}.
The \texttt{SimpleSharedEntity}\index{SimpleSharedEntity@{\texttt{SimpleSharedEntity}}}
class implements the shared entity algorithms, that subclasses can redefine if they want.

Hotmoka models validator nodes as
objects of class \texttt{Validator}\index{Validator@{\texttt{Validator}}},
that are externally owned accounts with an extra identifier
(Fig.~\ref{fig:entities_hierarchy}).
In the specific case of a Hotmoka blockchain built over Tendermint, validators
are instances of the subclass
\texttt{TendermintED25519Validator}\index{TendermintED25519Validator@{\texttt{TendermintED25519Validator}}},
whose identifier is derived from their
ed25519 public key. This identifier is public information, reported
in the blocks or easily eavesdropped.
The \texttt{Validators}\index{Validators@{\texttt{Validators}}}
interface in Fig.~\ref{fig:entities_hierarchy}
extends the \texttt{SharedEntity} interface, fixes the shareholders
to be instances of \texttt{Validator} and adds a method
\texttt{getStake()} that yields the amount of coins
at stake for each given validator (if the validator misbehaves, its stake will
be slashed).

The \texttt{AbstractValidators}\index{AbstractValidators@{\texttt{AbstractValidators}}}
class implements the set of validators and the distribution
of the reward and is a subclass of \texttt{SimpleSharedEntity} (Fig.~\ref{fig:entities_hierarchy}).
Shares are voting power in this case. It has a subclass
for each kind of Hotmoka node, so that the distribution of the reward at each
block creation can be implemented differently in each node type.
Namely, there exist subclasses
\texttt{TendermintValidators}\index{TendermintValidators@{\texttt{TendermintValidators}}},
\texttt{MokamintValidators}\index{MokamintValidators@{\texttt{MokamintValidators}}} and
\texttt{DiskValidators}\index{DiskValidators@{\texttt{DiskValidators}}}.
The first subclass restricts the type of the validators to be
\texttt{TendermintED25519Validator}. At each
block committed, Hotmoka calls the reward method of such subclasses in order
to reward the validators (if any) that behaved correctly and slash those that
misbehaved, possibly removing them from the set of validators. Moreover, such methods
are responsible for minting new coins at each block creation.
In the case of Tendermint nodes, at block creation time,
Hotmoka calls method \texttt{getShares()} and informs
the underlying Tendermint engine about the identifiers of the validator nodes
for the next blocks. Tendermint expects such validators to mine and vote the
subsequent blocks, until a change in the set of validators occurs.

\section{Disk nodes}\label{sec:disk_nodes}

The Hotmoka nodes of the previous sections form a real blockchain.
They are perfect for deploying a blockchain where we can program smart contracts in
Takamaka. Nevertheless, they are slow for debugging: transactions are committed every few seconds,
by default. Hence, if we want to see the result of a transaction,
we have to wait for some seconds at least.
Moreover, Tendermint does not allow one to see the effects of each single transaction,
in a simple way. For testing, debugging and didactical purposes, it would be simpler to have a light node
that behaves like a blockchain, allows access to blocks and transactions as text files,
but is not a blockchain. This is the goal of the \texttt{DiskNode}s.\index{DiskNode@{\texttt{DiskNode}}}
They are not part of an actual blockchain since they do not propagate transactions
in a peer-to-peer network, on which consensus is imposed. But they are very
handy because they allow one to inspect, very easily, the requests sent to
the node and the corresponding responses.

You can start a disk Hotmoka node, with an open faucet, exactly as you did,
in the previous sections for a Mokamint or Tendermint node, but using the \texttt{moka nodes disk init}
command instead of \texttt{moka nodes [mokamint|tendermint] init}. You do not need any Mokamint or Tendermint configuration
this time, but still need a key to control the gamete of the node, that you can create
exactly as for the previous Hotmoka nodes.
You then specify the Base58-encoded public key when starting the node:
%
\index{moka!nodes disk init@{\texttt{nodes disk init}}}
\inputCommand{moka_nodes_disk_init}
\inputOutput{moka_nodes_disk_init}
%
Then, in another shell, you can bind the gamete and open the flow of the faucet, as we did
for the other kinds of Hotmoka nodes.

You should have noticed any apparent difference with the previous kinds of Hotmoka nodes,
but for the fact that this node is faster,
its default chain identifier is the empty string and it has no validators. Blocks and transactions are
inside the \texttt{chain} directory, that this time contains a nice textual representation of requests and
responses:
%
\inputCommand{tree_chain}
\inputOutput{tree_chain}

\begin{commentbox}
The exact ids and the number of these transactions will be different in your computer.
\end{commentbox}

There are blocks \texttt{b0},\ldots,\texttt{b7}, each containing a variable number of transactions.
Each transaction is reported with its id and the pair request/response that the node has computed
for it. They are text files, that you can open to understand what is happening inside the node.

The transactions shown above are those that have initialized the node and
opened the faucet. The last transaction inside the last block is a \emph{reward}
transaction, that distributes the earnings of the block to the (zero, for disk nodes) validators
and increases block height and number of transactions in the manifest.

Spend some time looking at the \texttt{request.txt} and \texttt{response.txt} files.
For instance, the transaction inside \texttt{b2} should be the one that created the gamete
account. Print its \texttt{request.txt} file:
%
\index{transaction!request}
\inputCommand{cat_gamete_creation_request}
\inputOutput{cat_gamete_creation_request}
%
You can see that this is a request to create a gamete: it specifies the initial amount of crypto coins
held in the gamete and the public key of the gamete, which is what we passed when we initialized the node
(in base64 format, since it is more compact, in general). Print its response now:
%
\index{transaction!response}
\inputCommand{cat_gamete_creation_response}
\inputOutput{cat_gamete_creation_response}
%
You can see that this response reports the storage reference of the gamete that has been created.
Moreover, responses typically report a set of \emph{updates}, as in this case.
Updates are the side-effects on the state of the node,
induced by the transaction. Each update is a triple, that specifies a change in the value
of a field of a storage object. In this case, the updates describe the initial
state of the gamete object; for instance, an update states that
the balance of the gamete has been set to the initial supply for the node;
another states that the \texttt{maxFaucet} field of the gamete has been set to 0: this might be modified
later through a transaction triggered by the \texttt{moka nodes faucet} command.

\section{Logs}\label{sec:logs}

The moka tool generates a \texttt{hotmoka.log.*}\index{hotmoka.log@{\texttt{hotmoka.log}}}\index{logs}
log file. Therefore, that file is generated also
for the \texttt{moka nodes} commants that initialize or resume a Hotmoka node.
In that case, the logs will report which transactions have been
processed, together with potential errors.
%
\begin{commentbox}
The \texttt{hotmoka.log} file is normally rotated across successive or very long executions of moka.
Therefore, look for files such as \texttt{hotmoka.log.0} or \texttt{hotmoka.log.1} to find the logs of the
specific execution of moka that you are interested in.
\end{commentbox}

The content of the logs, in the case of the execution of a Hotmoka node, might look like:
%
\inputCommand{cat_hotmoka_log}
\inputOutput{cat_hotmoka_log}

If you want to follow in real time what is happening inside your node,
you can run for instance \texttt{tail -f hotmoka.log.0}: this
will hang and print the new log entries as they are generated.
Assuming that you have a local node running in your machine, try for instance in another shell
to run \texttt{moka nodes manifest show}: you will see in the log all new entries related
to the execution of the methods to access
the information on the node printed by the last command.
%
\begin{commentbox}
Hotmoka nodes started with Docker disable the generation of the log files and dump
logs to the standard output, where they can be accessed with the \texttt{docker logs} command.
Therefore, they do not generate any \texttt{hotmoka.log} file. See next chapter for information.
\end{commentbox}

\section{Node decorators}\label{sec:node_decorators}

\begin{center}
(See the \texttt{io-hotmoka-tutorial-examples-runs} project in \texttt{\hotmokaRepo{}})
\end{center}

There are some frequent actions that can be performed in code on a Hotmoka node.
Typically, these actions consist in a sequence of transactions. A few examples are:
%
\begin{enumerate}
\item The creation of an externally owned account\index{account!creation}. This requires the creation
	of its private and public keys and the instantiation of an
	\texttt{io.takamaka.code.lang.ExternallyOwnedAccount}. It is not a difficult
	procedure, but it is definitely tedious and occurs frequently.
\item The installation of a jar\index{jar!installation} in a node. This requires a transaction for installing
	code in the node. It requires also to parse the jar into bytes and identify the
	number of gas units for the transaction, depending on the size of the jar.
\item The initialization of a node\index{node!initialization}. Namely, local nodes start empty, that is,
	their store does not contain anything at the beginning, not even their manifest
	object. This initialization is rather technical and detail might change in future
	versions of Hotmoka. Performing this initialization by hand leads to fragile
	and error-prone code.
\end{enumerate}

In all these examples, Hotmoka provides decorators\index{node!decorator},
that is, implementations of the
\texttt{Node} interface built from an existing \texttt{Node} object. A decorator is just an alias
of the decorated node, but adds some functionality or performs some action on it.
Fig.~\ref{fig:node_hierarchy} shows that there are decorators for each of the three
situations enumerated above.

In order to understand the use of node decorators and appreciate their existence,
let us write a Java class that creates a \texttt{DiskNode}, initially empty;
then it initializes that node; subsequently it installs our \texttt{io-hotmoka-tutorial-examples-family-\hotmokaVersion{}.jar}
file from Sec.~\ref{sec:calling_method} in the node and finally creates two accounts in the node.
We stress the fact that these actions
can be performed in code by using calls to the node interface (Fig.~\ref{fig:node_hierarchy}) or
through the moka tool. Here, however, we want to perform them
in code, simplified with the use of node decorators.

Create the following \texttt{Decorators.java} class inside the
\texttt{io.hotmoka.tutorial.examples.runs} package of the
\texttt{io-hotmoka-tutorial-examples-runs} project:
%
\index{DiskNodes@{\texttt{DiskNodes}}}
\index{DiskInitializedNodes@{\texttt{DiskInitializedNodes}}}
\index{JarsNodes@{\texttt{JarsNodes}}}
\index{AccountsNode@{\texttt{AccountsNodes}}}
\begin{codebox}\begin{javalst}
package io.hotmoka.tutorial.examples.runs;

import static io.hotmoka.constants.Constants.HOTMOKA_VERSION;
import static io.takamaka.code.constants.Constants.TAKAMAKA_VERSION;

import java.math.BigInteger;
import java.nio.file.Paths;
import java.security.KeyPair;

import io.hotmoka.crypto.Entropies;
import io.hotmoka.crypto.SignatureAlgorithms;
import io.hotmoka.helpers.AccountsNodes;
import io.hotmoka.helpers.JarsNodes;
import io.hotmoka.node.ConsensusConfigBuilders;
import io.hotmoka.node.disk.DiskInitializedNodes;
import io.hotmoka.node.disk.DiskNodeConfigBuilders;
import io.hotmoka.node.disk.DiskNodes;

public class Decorators {
 
  public static void main(String[] args) throws Exception {
    var config = DiskNodeConfigBuilders.defaults().build();

    // the path of the runtime Takamaka jar, inside Maven's cache
    var takamakaCodePath = Paths.get
      (System.getProperty("user.home")
      + "/.m2/repository/io/hotmoka/io-takamaka-code/" + TAKAMAKA_VERSION
      + "/io-takamaka-code-" + TAKAMAKA_VERSION + ".jar");

    // the path of the user jar to install
    var familyPath = Paths.get(System.getProperty("user.home")
      + "/.m2/repository/io/hotmoka/io-hotmoka-tutorial-examples-family/"
      + HOTMOKA_VERSION
      + "/io-hotmoka-tutorial-examples-family-" + HOTMOKA_VERSION + ".jar");

    // create a key pair for the gamete
    var signature = SignatureAlgorithms.ed25519();
    var entropy = Entropies.random();
    KeyPair keys = entropy.keys("mypassword", signature);
    var consensus = ConsensusConfigBuilders.defaults()
   	  .setInitialSupply(BigInteger.valueOf(1_000_000_000))
   	  .setPublicKeyOfGamete(keys.getPublic()).build();

	 try (var node = DiskNodes.init(config)) {
      // first decorator: store the io-takamaka-code jar
      // and create manifest and gamete
      var initialized = DiskInitializedNodes.of(node, consensus, takamakaCodePath);

      // second decorator: store the family jar: the gamete will pay for that
      var nodeWithJars = JarsNodes.of(node, initialized.gamete(), keys.getPrivate(), familyPath);

      // third decorator: create two accounts, the first with 10,000,000 coins
      // and the second with 20,000,000 units of coin; the gamete will pay
      var nodeWithAccounts = AccountsNodes.of
        (node, initialized.gamete(), keys.getPrivate(),
        BigInteger.valueOf(10_000_000), BigInteger.valueOf(20_000_000));

      System.out.println("manifest: " + node.getManifest());
      System.out.println("family jar: " + nodeWithJars.jar(0));
      System.out.println("account #0: " + nodeWithAccounts.account(0) +
        "\n  with private key " + nodeWithAccounts.privateKey(0));
      System.out.println("account #1: " + nodeWithAccounts.account(1) +
        "\n  with private key " + nodeWithAccounts.privateKey(1));
    }
  }
}
\end{javalst}\end{codebox}
%
Run class \texttt{Decorators}:
%
\inputCommand{mvn_exec_decorators}
\inputOutput{mvn_exec_decorators}
%
As you can see, the use of decorators has avoided us the burden of
programming transaction requests, explicitly, and makes our code more robust,
since future versions of Hotmoka will update the implementation of the decorators,
while their interface will remain untouched, shielding our code from modifications.

As we have already said, decorators are
views of the same node, just seen through different lenses
(Java interfaces). Hence, further transactions can be run on
\texttt{node} or \texttt{initialized} or \texttt{nodeWithJars} or \texttt{nodeWithAccounts},
with the same effects. Moreover, it is not necessary to close all such nodes: closing \texttt{node} at
the end of the try-with-resource will actually close all of them, since they are the same node.

There exist classes for initializing other kinds of Hotmoka nodes in code, such as the classes
\texttt{MokamintInitializedNodes}\index{MokamintInitializedNodes@{\texttt{MokamintInitializedNodes}}}
and \texttt{TendermintInitializedNodes}\index{TendermintInitializedNodes@{\texttt{TendermintInitializedNodes}}}.

\section{Node services}\label{sec:node_services}

\begin{center}
(See the \texttt{io-hotmoka-tutorial-examples-runs} project in \texttt{\hotmokaRepo{}})
\end{center}

This section shows how we can publish a Hotmoka node online, by using Java code,
so that it becomes a
network service that can be used, concurrently, by many remote clients.
Namely, we will show how to publish a blockchain node based on Tendermint, but the code
is similar if you want to publish a memory Hotmoka node or any other Hotmoka node.

Remember that we have already published our nodes online, as network services,
by using the command \texttt{moka nodes [disk|mokamint|tendermint] init}.
Here, however, we want to do the same operation in code.

Create a class \texttt{Publisher.java} inside the package
\texttt{io.hotmoka.tutorial.examples.runs}
of the \texttt{io-hotmoka-tutorial-examples-runs} project.
Use the following code for the class:
%
\index{TendermintNodes@{\texttt{TendermintNodes}}}
\index{NodeServices@{\texttt{NodeServices}}}
\begin{codebox}\begin{javalst}
package io.hotmoka.tutorial.examples.runs;

import java.math.BigInteger;
import java.nio.file.Paths;
import java.security.KeyPair;

import io.hotmoka.crypto.Entropies;
import io.hotmoka.crypto.SignatureAlgorithms;
import io.hotmoka.node.service.NodeServices;
import io.hotmoka.node.tendermint.TendermintConsensusConfigBuilders;
import io.hotmoka.node.tendermint.TendermintInitializedNodes;
import io.hotmoka.node.tendermint.TendermintNodeConfigBuilders;
import io.hotmoka.node.tendermint.TendermintNodes;
import io.takamaka.code.constants.Constants;

public class Publisher {
  public static void main(String[] args) throws Exception {
    var config = TendermintNodeConfigBuilders.defaults().build();

    // the path of the runtime Takamaka jar, inside Maven's cache
    var takamakaCodePath = Paths.get
      (System.getProperty("user.home") +
      "/.m2/repository/io/hotmoka/io-takamaka-code/" + Constants.TAKAMAKA_VERSION +
      "/io-takamaka-code-" + Constants.TAKAMAKA_VERSION + ".jar");

    // create a key pair for the gamete
    var signature = SignatureAlgorithms.ed25519();
    var entropy = Entropies.random();
    KeyPair keys = entropy.keys("password", signature);
    var consensus = TendermintConsensusConfigBuilders.defaults()
      .setPublicKeyOfGamete(keys.getPublic())
      .setInitialSupply(BigInteger.valueOf(100_000_000))
      .build();

    try (var original = TendermintNodes.init(config);
      // uncomment the next line if you want to publish an initialized node
      // var initialized = TendermintInitializedNodes.of(original, consensus, takamakaCodePath);
      var service = NodeServices.of(original, 8001)) {

      System.out.println("\nPress ENTER to turn off the server and exit this program");
      System.in.read();
    }
  }
}
\end{javalst}\end{codebox}
%
We have already seen that \texttt{original} is a Hotmoka node based on Tendermint.
The following line makes the feat:
%
\begin{codebox}\begin{javalst}
var service = NodeServices.of(original, 8001);
\end{javalst}\end{codebox}
%
Variable \texttt{service} holds a Hotmoka \emph{node service}, that is, an actual network service that adapts
the \texttt{original} node to a web API that is published at localhost, at port 8001.
The service is an \texttt{AutoCloseable} object: it starts when it is created and gets shut down 
when its \texttt{close()} method is invoked, which occurs, implicitly, at the end of the
scope of the try-with-resources. Hence, this service remains online until the user
presses the ENTER key and terminates the service (and the program).

Run class \texttt{Publisher}:
%
\inputCommand{mvn_exec_publisher}
%
It should work for a few seconds and then start waiting for the ENTER key. Do not press such key yet!
Since \texttt{original} is not initialized yet, it has no manifest and no gamete. Its store is just empty
at the moment. You can verify that by running \texttt{moka nodes manifest show}, whose result should be:
%
\begin{shellbox}\begin{ttlst}
The remote service is misbehaving: are you sure that it is actually published at ws://localhost:8001 and that it is initialized and accessible?
\end{ttlst}\end{shellbox}
%
since it cannot find a manifest in the node.

Therefore, let us initialize the node before publishing it, so that it is already
initialized when published. Press ENTER to terminate the service, then modify
the \texttt{Publisher.java} class by uncommenting the use of the \texttt{InitializedNode} decorator,
whose goal is to create manifest and gamete of the node
and install the basic classes of the Takamaka runtime inside the node.
%
\begin{commentbox}
Note that we have published \texttt{original}:
%
\begin{codebox}\begin{javalst}
var service = NodeServices.of(original, 8001);
\end{javalst}\end{codebox}
%
but we could have published \texttt{initialized} instead:
%
\begin{codebox}\begin{javalst}
var service = NodeServices.of(initialized, 8001);
\end{javalst}\end{codebox}
%
The result would be the same, since both are views of the same node object.
Moreover, note that we have initialized the node inside the try-with-resources,
before publishing the service as the last of the three resources.
This ensures that the node, when published, is already initialized.
In principle, publishing an uninitialized node, as done previously, exposes
to the risk that somebody else might initialize the node, hence taking its control
since he will set the keys of the gamete.
\end{commentbox}

If you re-run class \texttt{Publisher} now and retry the \texttt{moka nodes manifest show} command, you should see
the manifest of the now initialized node on the screen.
%
\begin{commentbox}
A Hotmoka node, once published, can be accessed by many
users, \emph{concurrently}. This is not a problem, since Hotmoka nodes are thread-safe and can
be used in parallel by many users. Of course, this does not mean that there are no
race conditions at the application level. As a simple example, if two users operate
with the same paying externally owned account, their wallets might suffer from race
conditions on the nonce of the account and they might see requests
rejected because of an incorrect nonce. The situation is the same here as in Ethereum,
for instance. In practice, each externally owned account should be controlled
by a single wallet at a time.
\end{commentbox}

\section{Remote nodes}\label{sec:remote_nodes}

A service can be published and its methods can be called through JSON queries.
This is relatively easy for methods such as \texttt{getManifest()} and
\texttt{getConfig()} of the interface \texttt{Node}. However, it
becomes harder if we want to call methods of \texttt{Node} that need parameters, such
as \texttt{getState()} or the many add/post/run methods for scheduling transactions on
the node. Parameters should be passed as JSON payload of the websockets connection, in a format
that is hard to remember, easy to get wrong and possibly changing in the future.
Moreover, the JSON responses must be parsed back.
In principle, this can be done by hand or through software that builds the
requests for the server and interprets its responses.
Nevertheless, it is not the suggested way to proceed.

A typical solution to this problem is to provide a software SDK, that is, a library
that takes care of serializing the requests into JSON and deserializing
the responses from JSON. Roughly speaking, this is the approach taken in Hotmoka.
More precisely, we can forget about the details of the JSON serialization
and deserialization of requests and responses and only program against the \texttt{Node} interface,
by using an adaptor of a published Hotmoka service into a \texttt{Node}. This adaptor is called
a \emph{remote} Hotmoka node\index{node!remote}.

We have used remote nodes from the very beginning of this tutorial.
Namely, if you go back to Sec.~\ref{sec:jar_installation},
you will see that we have built a Hotmoka node from a remote service:
%
\index{RemoteNodes@{\texttt{RemoteNodes}}}
\begin{codebox}\begin{javalst}
try (var node = RemoteNodes.of(new URI(args[0]), 150000)) {
  ...
}
\end{javalst}\end{codebox}
%
The \texttt{RemoteNodes.of(...)} method adapts a remote service into a Hotmoka node,
so that we can call all its methods (Fig.~\ref{fig:node_hierarchy}). The
\texttt{150000} parameter is the timeout, in milliseconds, for connecting to the service
and for the methods called on the remote node.

\section{Sentry nodes}\label{sec:sentry_nodes}

We have seen that a \texttt{Node} can be published as a Hotmoka service:
in a machine \texttt{my.validator.com} we can execute:
%
\begin{codebox}\begin{javalst}
TendermintNodeConfig config = TendermintNodeConfigBuilders.defaults().build();

try (Node original = TendermintNodes.init(config);
  NodeService service = NodeServices.of(original, 8001)) {
  ...
}
\end{javalst}\end{codebox}
%
The service will be published on the internet at \url{ws://my.validator.com:8001}.
Moreover, in another machine \texttt{my.sentry.com},
that Hotmoka service can be adapted into a remote node
that, itself, can be published on that machine:
%
\begin{codebox}\begin{javalst}
try (Node validator = RemoteNodes.of(URI.create("ws://my.validator:8001"), 80000);
  NodeService service = NodeServices.of(validator, 8001)) {
  ...
}
\end{javalst}\end{codebox}
%
The service will be published at \url{ws://my.sentry.com:8001}.

We can continue this process as much as we want, but let us stop at this point.
Programmers can connect to the service published at
\url{ws://my.sentry.com:8001} and send requests to it. That service is just a bridge
that forwards everything to the service at \url{ws://my.validator.com:8001}.
It might not be immediately clear why this intermediate step could be useful
or desirable. The motivation is that we could keep the (precious) validator
machine under a firewall that allows connections with \texttt{my.sentry.com} only.
As a consequence, in case of DOS attacks, the sentry node will receive
the attack and possibly crash, while the validator continues to operate as usual:
it will continue to interact with the other validators and take part in the validation
of blocks. Moreover, since many sentries can be connected to a single validator, the latter
remains accessible through the other sentries, if needed.
This is an effective way to mitigate the problem of DOS attacks to validator nodes.

The idea of using sentry nodes against DOS attacks is not new for proof-of-stake networks,
whose validators are considered as precious resources that must be protected. It is used, for
instance, in Cosmos networks~\cite{CosmosSentry}.
However, note how it is easy, with Hotmoka, to build such a network architecture
by using network services and remote nodes.

\section{Signatures and quantum-resistance}\label{sec:quantum}

Hotmoka is agnostic \wrt{} the algorithm used for signing requests. This means that it is
possible to deploy Hotmoka nodes that sign requests with distinct signature algorithms.
Of course, if nodes must re-execute the same transactions, such as in the case of a
blockchain, then all nodes of the blockchain must use the same algorithm for
the transactions signed by each given account, or otherwise
they will not be able to reach consensus.
Yet, any fixed algorithm can be chosen for each account. In principle, it is even possible to use
an algorithm that does not sign the transactions, if the identity of the callers of the
transactions needn't be verified. However, this might be sensible in private networks only.

The default signature algorithm used by a node is specified at construction time, as a configuration
parameter. For instance, the code\index{setSignatureForRequests()@{\texttt{setSignatureForRequests()}}}
%
\begin{codebox}\begin{javalst}
var config = TendermintNodeConfigBuilders.defaults().build();
var consensus = TendermintConsensusConfigBuilders.defaults()
  .setPublicKeyOfGamete(keys.getPublic())
  .setInitialSupply(SUPPLY)
  ...
  .setSignatureForRequests(SignatureAlgorithms.ed25519()) // this is the default
  .build();

try (var node = TendermintNodes.init(config);
     var initialized = TendermintInitializedNodes.of(node, consensus, takamakaCodePath)) {
  ...
}
\end{javalst}\end{codebox}
%
starts a Tendermint-based blockchain node that uses the ed25519 signature algorithm
as default signature algorithm for the requests.
Requests sent to that node can be signed as follows:
%
\begin{codebox}\begin{javalst}
// recover the algorithm used by the node
SignatureAlgorithm signature = node.getConfig().getSignatureForRequests();

// create a key pair for that algorithm
KeyPair keys = signature.getKeyPair();

// create a signer object with the private key of the key pair
Signer<SignedTransactionRequest<?>> signer = signature.getSigner
  (keys.getPrivate(), SignedTransactionRequest<?>::toByteArrayWithoutSignature);

// create an account having public key keys.getPublic()
var account = ....

// create a transaction request on behalf of the account
ConstructorCallTransactionRequest request
  = TransactionRequests.constructorCall(signer, account, ...);

// send the request to the node
node.addConstructorCallTransaction(request);
\end{javalst}\end{codebox}
%
In the example above, we have explicitly specified
to use ed25519 as default signature algorithm. That is what is chosen
if nothing is specified at configuration-time.
Consequently, there is no need to specify that algorithm in the
configuration object and that is why we never did it in the previous chapters.
But it is possible to configure nodes with other default signature algorithms.
For instance:
%
\begin{codebox}\begin{javalst}
var consensus = TendermintConsensusConfigBuilders.defaults()
  .setPublicKeyOfGamete(keys.getPublic())
  .setInitialSupply(SUPPLY)
  ...
  .setSignatureForRequests(SignatureAlgorithms.sha256dsa()) // this replaces the default
  .build();
\end{javalst}\end{codebox}
%
configures a node that uses sha256dsa as default signature algorithm, while
%
\begin{codebox}\begin{javalst}
var consensus = TendermintConsensusConfigBuilders.defaults()
  .setPublicKeyOfGamete(keys.getPublic())
  .setInitialSupply(SUPPLY)
  ...
  .setSignatureForRequests(SignatureAlgorithms.empty())
  .build();
\end{javalst}\end{codebox}
%
configures a node that uses the empty signature as default signature algorithm; it is an
algorithm that accepts all signatures, in practice disabling signature checking.

It is possible to specify a quantum-resistant signature algorithm\index{quantum resistance} as default,
that is, one that belongs to
a family of algorithms that are expected to be immune from attacks performed through
a quantistic computer. For instance,
%
\begin{codebox}\begin{javalst}
var consensus = TendermintConsensusConfigBuilders.defaults()
  .setPublicKeyOfGamete(keys.getPublic())
  .setInitialSupply(SUPPLY)
  ...
  .setSignatureForRequests(SignatureAlgorithms.qtesla1())
  .build();
\end{javalst}\end{codebox}
%
configures a node that uses the quantum-resistant qtesla-p-I algorithm as default signature algorithm,
while
%
\begin{codebox}\begin{javalst}
var consensus = TendermintConsensusConfigBuilders.defaults()
  .setPublicKeyOfGamete(keys.getPublic())
  .setInitialSupply(SUPPLY)
  ...
  .setSignatureForRequests(SignatureAlgorithms.qtesla3())
  .build();
\end{javalst}\end{codebox}
%
configures a node that uses the quantum-resistant qtesla-p-III
algorithm as default signature algorithm, that is expected to be more resistant than
qtesla-p-I but has larger signatures than qtesla-p-I.

Quantum-resistance is an important aspect of future-generation blockchains.
However, at the time of this writing, a quantum attack is mainly a theoretical
possibility, while the large size of quantum-resistant keys and signatures is
already a reality and a node using a qtesla signature algorithm \emph{as default}
might exhaust the disk space of your computer very quickly. In practice, it is better
to use a quantum-resistant signature algorithm only for a subset of the transactions, whose
quantum-resistance is deemed important. Instead, one should use a lighter algorithm
(such as the default ed25519) for all other transactions. This is possible because
Hotmoka nodes allow one to mix transactions signed with distinct algorithms.
Namely, one can use ed25519 as default algorithm, for all transactions signed
by instances of \texttt{ExternallyOwnedAccount}s,
with the exception of those transactions that are signed by instances of
the interface \texttt{AccountQTESLA1}\index{AccountQTESLA1@{\texttt{AccountQTESLA1}}},
such as the class \texttt{ExternallyOwnedAccountQTESLA1}\index{ExternallyOwnedAccountQTESLA1@{\texttt{ExternallyOwnedAccountQTESLA1}}},
or of the interface \texttt{AccountQTESLA3}\index{AccountQTESLA3@{\texttt{AccountQTESLA3}}},
such as the class \texttt{ExternallyOwnedAccountQTESLA3}\index{ExternallyOwnedAccountQTESLA3@{\texttt{ExternallyOwnedAccountQTESLA3}}},
or of the interface \texttt{AccountSHA256DSA}\index{AccountSHA256DSA@{\texttt{AccountSHA256DSA}}},
such as the class \texttt{ExternallyOwnedAccountSHA256DSA}\index{ExternallyOwnedAccountSHA256DSA@{\texttt{ExternallyOwnedAccountSHA256DSA}}}
(see Fig.~\ref{fig:contract_hierarchy}).
Namely, if the caller of a transaction is an \texttt{AccountQTESLA1}, then the
request of the transaction must be signed with the qtesla-p-I algorithm.
If the caller of a transaction is an \texttt{AccountQTESLA3}, then the
request of the transaction must be signed with the qtesla-p-III algorithm.
If the caller of a transaction is an \texttt{AccountSHA256DSA}, then the
request of the transaction must be signed with the sha256dsa algorithm.
If the caller of a transaction is an \texttt{AccountED25519}, then the
request of the transaction must be signed with the ed25519 algorithm.
In practice, this allows specific transactions to override the default signature
algorithm for the node.

Let us for instance create an account that uses the default signature algorithm for the node.
We charge its creation to the faucet of the node:
%
\index{moka!keys create@{\texttt{keys create}}}
\inputCommand{moka_keys_create_account7}
\inputOutput{moka_keys_create_account7}
%
\index{moka!accounts create@{\texttt{accounts create}}}
\inputCommand{moka_accounts_create_account7}
\inputOutput{moka_accounts_create_account7}
%
You can check the class of the new account with the \texttt{moka objects show} command:
%
\index{ExternallyOwnedAccountED25519@{\texttt{ExternallyOwnedAccountED25519}}}
\index{moka!objects show@{\texttt{objects show}}}
\inputCommand{moka_objects_show_account7}
\inputOutput{moka_objects_show_account7}
%
As you can see, an account has been created, that uses the default ed25519
signature algorithm of the node.
Assume that we want to create an account now, that always uses the sha256dsa signature algorithm instead,
regardless of the default signature algorithm of the node. We can specify that when invoking the
\texttt{moka accounts create} command:
%
\index{moka!keys create@{\texttt{keys create}}}
\inputCommand{moka_keys_create_account8}
\inputOutput{moka_keys_create_account8}
%
\index{moka!accounts create@{\texttt{accounts create}}}
\inputCommand{moka_accounts_create_account8}
\inputOutput{moka_accounts_create_account8}
%
This creation has been more expensive than for the previous account, because the public key of the
sha256dsa algorithm is much longer than that for the ed25519 algorithm.
You can verify this with the \texttt{moka objects show} command:
%
\index{moka!objects show@{\texttt{objects show}}}
\inputCommand{moka_objects_show_account8}
\inputOutput{moka_objects_show_account8}
%
Note that the class of the account is \texttt{ExternallyOwnedAccountSHA256DSA} this time.

Let us create an account that uses the qtesla-p-I signature algorithm now:
%
\index{moka!keys create@{\texttt{keys create}}}
\inputCommand{moka_keys_create_account9}
\inputOutput{moka_keys_create_account9}
%
\index{moka!accounts create@{\texttt{accounts create}}}
\inputCommand{moka_accounts_create_account9}
\inputOutput{moka_accounts_create_account9}
%
The creation of this account has been still more expensive, since this kind of quantum-resistant
keys are very large. Again, you can use the \texttt{moka object show}
command to verify that it has class \texttt{ExternallyOwnedAccountQTESLA1}.

Finally, let us use the previous qtesla-p-I account to create a qtesla-p-III account:
%
\index{moka!keys create@{\texttt{keys create}}}
\inputCommand{moka_keys_create_account10}
\inputOutput{moka_keys_create_account10}
%
\index{moka!accounts create@{\texttt{accounts create}}}
\inputCommand{moka_accounts_create_account10}
\inputOutput{moka_accounts_create_account10}
%
Note, again, the extremely high gas cost of this creation.

Regardless of the kind of account, their use is always the same.
The only difference is to use the right signature algorithm when signing
a transaction, since it must match that of the caller account. This is automatic, if we
use the moka tool. For instance, let us use our qtesla-p-I account to install
the \texttt{io-hotmoka-tutorial-examples-family-\hotmokaVersion{}.jar} file from
Sec.~\ref{sec:calling_method} in the node:
%
\index{moka!jars install@{\texttt{jars install}}}
\inputCommand{moka_jars_install_family_quantum}
\inputOutput{moka_jars_install_family_quantum}
%
The moka tool has understood that the payer is an account that signs with the
qtesla-p-I algorithm and has signed the request accordingly.